# =============================================================================
# Deep-Bot Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control (it's in .gitignore)
#
# Usage:
#   1. Copy this file: cp .env.example .env
#   2. Edit .env with your actual API keys and configuration
#   3. Run the bot: python bot.py
# =============================================================================

# -----------------------------------------------------------------------------
# REQUIRED: Discord Configuration
# -----------------------------------------------------------------------------
# Get these from https://discord.com/developers/applications
DISCORD_TOKEN=your_discord_bot_token_here
DISCORD_CLIENT_ID=your_discord_client_id_here

# Optional: Restrict bot to specific guild (server)
# Leave empty to allow bot in all guilds
DISCORD_GUILD_ID=

# -----------------------------------------------------------------------------
# REQUIRED: AI Provider Configuration
# -----------------------------------------------------------------------------
# At least one AI provider API key is required

# OpenAI API Key (get from https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-your_openai_api_key_here

# Anthropic API Key (get from https://console.anthropic.com/)
# Optional if using OpenAI only
ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here

# -----------------------------------------------------------------------------
# REQUIRED: Bot Owner Configuration
# -----------------------------------------------------------------------------
# Your Discord user ID (right-click your profile > Copy ID)
# This user will have access to admin commands
BOT_OWNER_ID=your_discord_user_id_here

# -----------------------------------------------------------------------------
# Bot Configuration
# -----------------------------------------------------------------------------
# Command prefix for bot commands (default: !)
BOT_PREFIX=!

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Debug mode (true/false) - enables additional logging
DEBUG_MODE=false

# Test mode (true/false) - enables test-specific behavior
TEST_MODE=false

# -----------------------------------------------------------------------------
# Security: Blacklist Configuration
# -----------------------------------------------------------------------------
# Comma-separated list of Discord user IDs to exclude from AI responses
# Example: BLACKLIST_IDS=123456789,987654321
# Leave empty for no blacklist
BLACKLIST_IDS=

# -----------------------------------------------------------------------------
# Discord Message Fetching Configuration
# -----------------------------------------------------------------------------
# Delay between message fetches (seconds) - prevents rate limiting
MESSAGE_FETCH_DELAY=0.2

# Number of messages to fetch per batch
MESSAGE_FETCH_BATCH_SIZE=100

# Report progress every N messages (for long loads)
MESSAGE_FETCH_PROGRESS_INTERVAL=100

# Maximum retries for failed message fetches
MESSAGE_FETCH_MAX_RETRIES=5

# -----------------------------------------------------------------------------
# Chunking Strategy Configuration
# -----------------------------------------------------------------------------
# Default chunking strategies to use (comma-separated)
# Options: single, temporal, conversation, sliding_window, author, tokens
# Recommended: single,tokens (fastest, covers most use cases)
CHUNKING_DEFAULT_STRATEGIES=single,tokens,author

# Temporal chunking: Time window in seconds (default: 3600 = 1 hour)
CHUNKING_TEMPORAL_WINDOW=3600

# Conversation chunking: Gap between messages in seconds (default: 1800 = 30 min)
CHUNKING_CONVERSATION_GAP=1800

# Sliding window: Number of messages per window
CHUNKING_WINDOW_SIZE=10

# Sliding window: Number of overlapping messages between windows
CHUNKING_OVERLAP=2

# Token-aware chunking: Maximum tokens per chunk
CHUNKING_MAX_TOKENS=512

# Minimum number of messages per chunk
CHUNKING_MIN_CHUNK_SIZE=3

# -----------------------------------------------------------------------------
# Vector Store Configuration
# -----------------------------------------------------------------------------
# Vector store provider: "chroma" (default) or "pinecone" (not yet implemented)
VECTOR_STORE_PROVIDER=chroma

# -----------------------------------------------------------------------------
# Embedding Configuration
# -----------------------------------------------------------------------------
# Number of documents to embed per batch (prevents memory/rate limit issues)
EMBEDDING_BATCH_SIZE=100

# Delay between embedding batches in seconds (rate limiting)
EMBEDDING_BATCH_DELAY=0.1

# -----------------------------------------------------------------------------
# RAG (Retrieval-Augmented Generation) Configuration
# -----------------------------------------------------------------------------
# Default number of chunks to retrieve for RAG queries
RAG_DEFAULT_TOP_K=10

# Minimum similarity score threshold (0.0 to 1.0)
# Lower = more results, Higher = more relevant results
RAG_DEFAULT_SIMILARITY_THRESHOLD=0.01

# Maximum context tokens to send to LLM (includes prompt + retrieved chunks)
RAG_DEFAULT_MAX_CONTEXT_TOKENS=4000

# Default temperature for LLM responses (0.0 to 2.0)
# 0.0 = deterministic, 2.0 = very creative
# Note: Automatically normalized across providers (0.7 = 70% creativity)
RAG_DEFAULT_TEMPERATURE=0.7

# Default chunking strategy for RAG queries
# Options: single, temporal, conversation, sliding_window, author, tokens
RAG_DEFAULT_STRATEGY=author

# =============================================================================
# Notes:
# =============================================================================
# - All numeric values can be integers or floats as appropriate
# - Boolean values: use "true" or "false" (case-insensitive)
# - Empty values use defaults defined in config.py
# - For production, use environment variables or a secrets manager
#   instead of .env file for sensitive values
# =============================================================================

# RAG Advanced Technique Settings
# Enable/disable advanced RAG techniques (true/false)
# These can also be changed dynamically via !rag_set command

# Hybrid Search: Combines BM25 (keyword) and vector (semantic) search
RAG_USE_HYBRID_SEARCH=true

# Multi-Query: Generates multiple query variations for better recall
RAG_USE_MULTI_QUERY=true

# HyDE: Hypothetical Document Embeddings - generates hypothetical answer for better retrieval
RAG_USE_HYDE=true

# Reranking: Uses cross-encoder to re-rank initial results for better precision
RAG_USE_RERANKING=true

# Maximum output tokens for RAG responses (default: 1000)
RAG_MAX_OUTPUT_TOKENS=1000
